# 1. Сбор данных: используйте открытые датасеты для обучения и тестирования модели. Предложите свои варианты и критерии выбора. 
Самый простой вариант для прототипа: датасет cedr. 
Недостатки:
- небольшой размер
- несбалансированность
- сложность в разметке из-за отсутствия расширенного контекста (тексты короткие, в то же время, длинные тексты часто содержат широкий диапазон эмоций)

Датасет можно расширить с помощью переводного датасета текстов с платформы Reddit, "Djacon/ru_goemotions".
Еще один способ расширения - создание текстов моделью перефразирования.
Некоторые фразы несут сложный эмоциональный окрас, так что неслучайно в датасете cedr задача ставится как многозначная классификация - некоторые экземпляры принадлежат к нескольким классам одновременно
# 2. Предобработка данных: выполните очистку данных, опишите пайплайн по предобработке.
Орфографические исправления не имеют большого смысла, так как не стоит ожидать высокого уровня грамотности от пользователей.  
Самый простой метод улучшения датасета - дедупликация. Два датасета в данном исследовании имеют довольно высокое качество и не содержат прямых дубликатов.  

Самый масштабируемый вариант дальнейшего улучшения связан с обучением модели и последующим исследованием результатов модели как на обучающей, так и на валидационной выборках:
- Если допустить переобучение модели на обучающей выборке, ошибки, которые модель продолжает совершать на обучающей выборке будут  означать либо ошибку в разметке, либо сложные примеры/"выбросы", которые могут лежать на границе распределения класса, к которому относится текст. Впрочем, не стоит забывать, что для любого датасета существует количество параметров модели, которого достаточно, чтобы полностью "запомнить" все экземпляры, поэтому размер модели при таком анализе должен быть относительно небольшой и соответствовать размеру датасета.  
- При нормальном обучении модели, когда мы не допускаем переобучения, ошибки на валидации более вероятно связаны с несовершенством модели, но и здесь могут обнаружить ошибки разметки. В данном случае для анализа можно использовать более параметризованную модель, чем в предыдущем пункте.

Впрочем, при визуальном анализе ошибок моделей мы наблюдаем, сложность разметки небольших текстов: например, в категории "злость" значительная часть ложно-положительных результатов модели содержат слова "злоба", "злость" и т. д.
# 3. Моделирование: Используйте подходы на основе нейронных сетей для классификации текста (например, fasttext, LSTM, CNN, BERT). Вы можете использовать предобученные модели и адаптировать их к вашей задаче, или обучить свою модель с нуля. Выбор модели нужно объяснить. В случае с трансформерами, при желании укажите какую схему файнтьюнинга выбираете и почему.
Данная задача сводится к классификации небольших текстов, поэтому очевидное решение - модели типа "только энкодер", обученные на русских или мультиязычных наборах текстов. Значительное увеличение размера может дать несколько процентов прироста в сравнении с небольшими дистиллированными моделями, так что нужно дополнительное понимание, что важнее для бизнес-логики: скорость работы или небольшое улучшение понимания настроения пользователя.

Для оценки будут использованы модели из пула Huggingface "cointegrated/rubert-tiny2" и "xlm-roberta-base".
# 4. Оценка: Оцените производительность вашей модели, используя соответствующие метрики (например, точность, полноту, roc_auc, F1-меру).
В условиях несбалансированности датасета модель неплохо характеризуется f-мерой с поклассовым подсчётом или ROC AUC "один-против-всех" как мерой способности отделять данный класс от остальных, но в реальности стоит ориентироваться на бизнес-логику - в чем причина появления данной модели в системе? 
Если мы хотим отслеживать любое агрессивное поведение, тогда нас интересует полнота класса "злость". 
Если нас интересует настроение человека при взаимодействии с маркетинговой кампанией - нам интересен precision классов "грусть" и "радость". Обнаружение всех экземпляров не так важно, если мы получаем много ложных срабатываний.

Результаты модели "cointegrated/rubert-tiny2" на расширенном датасете:  
```
классы: ["нейтрально", "радость", "грусть", "surprise", "fear", "anger"]
поклассовый ROC AUC: [0.9145, 0.9651, 0.9444, 0.889, 0.9398, 0.8189] средний ROC AUC: 0.912  
поклассовая f-мера: [0.8541, 0.8922, 0.8771, 0.7782, 0.8123, 0.6671] средняя f-мера: 0.8135  
поклассовая Точность: [0.8599, 0.9017, 0.8924, 0.7803, 0.7946, 0.6461] средняя Точность: 0.8125  
поклассовая Полнота: [0.85, 0.8835, 0.8638, 0.7761, 0.833, 0.6986] средняя Полнота: 0.8175  
```

Результаты модели "xlm-roberta-base" на расширенном датасете:  
```
классы: ["нейтрально", "радость", "грусть", "surprise", "fear", "anger"]  
поклассовый ROC AUC: [0.9419, 0.9782, 0.9424, 0.9398, 0.9367, 0.8508] средний ROC AUC: 0.9316  
поклассовая f-мера: [0.8956, 0.9244, 0.8847, 0.8286, 0.8362, 0.6846] средняя f-мера: 0.8423  
поклассовая Точность: [0.8971, 0.9206, 0.8923, 0.8393, 0.8375, 0.6903] средняя Точность: 0.8462  
поклассовая Полнота: [0.8942, 0.9284, 0.8776, 0.8187, 0.8348, 0.6793] средняя Полнота: 0.8388  
```

# 5. Развертывание: Оберните вашу модель в микросервис с использованием FastAPI или создайте телеграм-бота. Модель должна быть доступна для запросов через HTTP API или через интерфейс бота. Сервис должен принимать на вход текстовое сообщение и возвращать его эмоциональный окрас. При желании подготовьте вашу модель для инференса или опишите как ее можно подготовить (оптимизации, квантинизация и тд)

Реализовано преобразование модели в формат ONNX и инференс получившейся модели через интерфейс Huggingface transformers.

Библиотека https://github.com/huggingface/optimum содержит интегрированный с экосистемой Huggingface метод квантизации после обучения и последующего инференса получившейся модели.

При инференсе больших моделей или очень большой нагрузке имеет смысл использовать triton server от Nvidia. Данное ПО выступает как оркестратор и балансер нагрузки на несколько GPU. Есть высокоуровневая библиотека для работы с ним - https://github.com/ELS-RD/transformer-deploy. 

# Описание данного пакета

Скрипт `replicate_models.sh` содержит примеры запуска обучения моделей с параметрами:  
--base-model может принимать значения `rubert` и `xlm` для обозначения двух доступных моделей  
--batch-size позволяет изменять размер обучающей выборки на каждом шаге обучения, впрочем, данный параметр не оказывает заметного влияния на качество обучения в существующей конфигурации  
--create-onnx обеспечивает конвертацию модели в формат ONNX после окончания обучения  
--dataset принимает значение `combo`, если необходимо обучение на расширенном датасете  
--epochs определяет сколько раз модель "увидит" полный датасет  
--evaluate-devset и --evaluate-testset определяют необходимость оценки модели на валидационной и тестовой выборках  
--extra-info параметр помогает записать дополнительный комментарий по поводу сохраняемой модели в название папки сохранения  
--lr определяет максимальный темп обучения модели  
--scheduler определяет изменение темпа обучения во время обучения модели. По умолчанию используется постоянный темп, а с параметром `cosine` происходит постепенное убывание темпа обучения  
--train-model указывает на необходимость обучения новой модели  
--weights-dir определяет путь сохранения весов модели после тренировки. По умолчанию используется папка `weights`.

Данный скрипт создает небольшую модель в 2 версиях: нормально обученную и переобученную, а также нормально обученную большего размера в форматах Huggingface и ONNX. 

# Запуск контейнера
После клонирования репозитория
```
git clone https://github.com/tetelias/emotion
bash download_weights.sh
```

Необходимо загрузить веса по адресу
```

```

Контейнер можно собрать командой
```
docker build -t docker_username/image_name .
```

Контейнер можно запустить командой
```
docker run -p 8000:8000 -v /absolute/path/to/weights/folder:/app/weights -it tetelias/emotion
```
После запуска контейнера нужно перейти по адресу `http://localhost:8000/docs` (вместо localhost может быть и удаленная машина, но тогда понадобится port forwarding для доступа к API). Это адрес документации запущенного API. Здесь можно выбрать модель, справа в верхнем углу формы выбрать "Try it out" и ввести текст для предсказания, нажать кнопку "Execute" и чуть ниже в разделе "Response body" увидеть предсказние класса и вероятность.

Контейнер также можно запустить командой
```
docker run --gpus all -p 8000:8000 -v /absolute/path/to/weights/folder:/app/weights -it tetelias/emotion bash
```

В этом случае после запуска контейнера появится доступ к консоли, где командой 
```
bash replicate_models.sh
```
можно воспроизвести обучение моделей.